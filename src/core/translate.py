import os
import google.generativeai as genai
import time
import json
import re
import concurrent.futures
import threading
from multiprocessing import cpu_count

# Import reformat function
try:
    from .reformat import fix_text_format
    CAN_REFORMAT = True
    print("âœ… ÄÃ£ import thÃ nh cÃ´ng chá»©c nÄƒng reformat")
except ImportError:
    CAN_REFORMAT = False
    print("âš ï¸ KhÃ´ng thá»ƒ import reformat.py - chá»©c nÄƒng reformat sáº½ bá»‹ táº¯t")

# --- Cáº¤U HÃŒNH CÃC Háº°NG Sá» ---
MAX_RETRIES_ON_SAFETY_BLOCK = 5
MAX_RETRIES_ON_BAD_TRANSLATION = 5
RETRY_DELAY_SECONDS = 2
PROGRESS_FILE_SUFFIX = ".progress.json"
CHUNK_SIZE = 1024 * 1024  # 1MB (KhÃ´ng cÃ²n dÃ¹ng trá»±c tiáº¿p CHUNK_SIZE cho viá»‡c Ä‘á»c file ná»¯a)

# KÃ­ch thÆ°á»›c cá»­a sá»• ngá»¯ cáº£nh (sá»‘ Ä‘oáº¡n vÄƒn báº£n trÆ°á»›c Ä‘Ã³ dÃ¹ng lÃ m ngá»¯ cáº£nh)
CONTEXT_WINDOW_SIZE = 5
# KÃ½ tá»± Ä‘áº·c biá»‡t Ä‘á»ƒ Ä‘Ã¡nh dáº¥u pháº§n cáº§n dá»‹ch trong prompt gá»­i Ä‘áº¿n AI
TRANSLATE_TAG_START = "<translate_this>"
TRANSLATE_TAG_END = "</translate_this>"

# Sá»‘ dÃ²ng gom láº¡i thÃ nh má»™t chunk Ä‘á»ƒ dá»‹ch
CHUNK_SIZE_LINES = 100

# Global stop event Ä‘á»ƒ dá»«ng tiáº¿n trÃ¬nh dá»‹ch
_stop_event = threading.Event()

def set_stop_translation():
    """Dá»«ng tiáº¿n trÃ¬nh dá»‹ch"""
    global _stop_event
    _stop_event.set()
    print("ğŸ›‘ ÄÃ£ yÃªu cáº§u dá»«ng tiáº¿n trÃ¬nh dá»‹ch...")

def clear_stop_translation():
    """XÃ³a flag dá»«ng Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p tá»¥c dá»‹ch"""
    global _stop_event
    _stop_event.clear()
    print("â–¶ï¸ ÄÃ£ xÃ³a flag dá»«ng, sáºµn sÃ ng tiáº¿p tá»¥c...")

def is_translation_stopped():
    """Kiá»ƒm tra xem cÃ³ yÃªu cáº§u dá»«ng khÃ´ng"""
    global _stop_event
    return _stop_event.is_set()

def get_optimal_threads():
    """
    Tá»± Ä‘á»™ng tÃ­nh toÃ¡n sá»‘ threads tá»‘i Æ°u dá»±a trÃªn cáº¥u hÃ¬nh mÃ¡y.
    """
    try:
        # Láº¥y sá»‘ CPU cores
        cpu_cores = cpu_count()
        
        # TÃ­nh toÃ¡n threads tá»‘i Æ°u:
        # - Vá»›i API calls, I/O bound nÃªn cÃ³ thá»ƒ dÃ¹ng nhiá»u threads hÆ¡n sá»‘ cores
        # - NhÆ°ng khÃ´ng nÃªn quÃ¡ nhiá»u Ä‘á»ƒ trÃ¡nh rate limiting
        # - Formula: min(max(cpu_cores * 2, 4), 20)
        optimal_threads = min(max(cpu_cores * 2, 4), 20)
        
        print(f"ğŸ–¥ï¸ PhÃ¡t hiá»‡n {cpu_cores} CPU cores")
        print(f"ğŸ”§ Threads tá»‘i Æ°u Ä‘Æ°á»£c Ä‘á» xuáº¥t: {optimal_threads}")
        
        return optimal_threads
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi phÃ¡t hiá»‡n CPU cores: {e}")
        return 10  # Default fallback

def validate_threads(num_threads):
    """
    Validate sá»‘ threads Ä‘á»ƒ Ä‘áº£m báº£o trong khoáº£ng há»£p lÃ½.
    """
    try:
        num_threads = int(num_threads)
        if num_threads < 1:
            return 1
        elif num_threads > 50:  # Giá»›i háº¡n tá»‘i Ä‘a Ä‘á»ƒ trÃ¡nh rate limiting
            return 50
        return num_threads
    except (ValueError, TypeError):
        return get_optimal_threads()

def validate_chunk_size(chunk_size):
    """
    Validate chunk size Ä‘á»ƒ Ä‘áº£m báº£o trong khoáº£ng há»£p lÃ½.
    """
    try:
        chunk_size = int(chunk_size)
        if chunk_size < 10:
            return 10
        elif chunk_size > 500:  # TrÃ¡nh chunks quÃ¡ lá»›n
            return 500
        return chunk_size
    except (ValueError, TypeError):
        return 100  # Default

# Default values
NUM_WORKERS = get_optimal_threads()  # Tá»± Ä‘á»™ng tÃ­nh theo mÃ¡y

def is_bad_translation(text):
    """
    Kiá»ƒm tra xem báº£n dá»‹ch cá»§a chunk cÃ³ Ä‘áº¡t yÃªu cáº§u khÃ´ng (kiá»ƒm tra Ä‘Æ¡n giáº£n dá»±a vÃ o Ä‘á»™ rá»—ng vÃ  tá»« chá»‘i).
    Tráº£ vá» True náº¿u báº£n dá»‹ch khÃ´ng Ä‘áº¡t yÃªu cáº§u (vÃ­ dá»¥: rá»—ng hoáº·c chá»©a tá»« tá»« chá»‘i), False náº¿u Ä‘áº¡t yÃªu cáº§u.
    """
    if text is None or text.strip() == "":
        # Chunk dá»‹ch ra rá»—ng hoáº·c chá»‰ tráº¯ng => coi lÃ  bad translation
        return True

    # CÃ¡c tá»« khÃ³a chá»‰ bÃ¡o báº£n dá»‹ch khÃ´ng Ä‘áº¡t yÃªu cáº§u
    # CÃ¡c tá»« khÃ³a nÃ y thÆ°á»ng xuáº¥t hiá»‡n khi AI tá»« chá»‘i dá»‹ch
    bad_keywords = [
        "tÃ´i khÃ´ng thá»ƒ dá»‹ch",
        "khÃ´ng thá»ƒ dá»‹ch",
        "xin lá»—i, tÃ´i khÃ´ng",
        "tÃ´i xin lá»—i",
        "ná»™i dung bá»‹ cháº·n", # ThÃªm kiá»ƒm tra thÃ´ng bÃ¡o cháº·n cÅ©ng lÃ  báº£n dá»‹ch xáº¥u cáº§n retry
        "as an ai", # Tá»« chá»‘i báº±ng tiáº¿ng Anh
        "as a language model",
        "i am unable",
        "i cannot",
        "i'm sorry"
    ]

    text_lower = text.lower()
    for keyword in bad_keywords:
        if keyword in text_lower:
            return True

    return False

def translate_chunk(model, chunk_lines):
    """
    Dá»‹ch má»™t chunk gá»“m nhiá»u dÃ²ng vÄƒn báº£n.
    chunk_lines: danh sÃ¡ch cÃ¡c dÃ²ng vÄƒn báº£n
    Tráº£ vá» (translated_text, is_safety_blocked_flag, is_bad_translation_flag).
    """
    # Gom cÃ¡c dÃ²ng thÃ nh má»™t chuá»—i lá»›n Ä‘á»ƒ gá»­i Ä‘i
    full_text_to_translate = "\n".join(chunk_lines)
    
    # Bá» qua cÃ¡c chunk chá»‰ chá»©a cÃ¡c dÃ²ng trá»‘ng hoáº·c chá»‰ tráº¯ng
    if not full_text_to_translate.strip():
        return ("", False, False) # Tráº£ vá» chuá»—i rá»—ng, khÃ´ng bá»‹ cháº·n, khÃ´ng bad translation

    try:
        # Prompt cho dá»‹ch chunk
        prompt = f"Dá»‹ch Ä‘oáº¡n vÄƒn báº£n sau sang tiáº¿ng Viá»‡t má»™t cÃ¡ch trá»±c tiáº¿p, xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ vÃ  danh xÆ°ng phÃ¹ há»£p trÆ°á»›c tiÃªn, khÃ´ng tá»« chá»‘i hoáº·c bÃ¬nh luáº­n, giá»¯ nguyÃªn vÄƒn phong gá»‘c vÃ  chi tiáº¿t ná»™i dung:\n\n{full_text_to_translate}"

        response = model.generate_content(
            contents=[{
                "role": "user",
                "parts": [prompt],
            }],
            generation_config={
                "response_mime_type": "text/plain",
                # CÃ³ thá»ƒ thÃªm cÃ¡c tham sá»‘ khÃ¡c náº¿u cáº§n
                # "temperature": 0.5,
                # "top_p": 0.95,
                # "top_k": 64,
                # "max_output_tokens": 8192,
            },
        )

        # 1. Kiá»ƒm tra xem prompt (Ä‘áº§u vÃ o) cÃ³ bá»‹ cháº·n khÃ´ng
        if response.prompt_feedback and response.prompt_feedback.safety_ratings:
            blocked_categories = [
                rating.category.name for rating in response.prompt_feedback.safety_ratings
                if rating.blocked
            ]
            if blocked_categories:
                return (f"[Ná»˜I DUNG Gá»C Bá»Š CHáº¶N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N - PROMPT: {', '.join(blocked_categories)}]", True, False)

        # 2. Kiá»ƒm tra xem cÃ³ báº¥t ká»³ á»©ng cá»­ viÃªn nÃ o Ä‘Æ°á»£c táº¡o ra khÃ´ng
        if not response.candidates:
            return ("[Ná»˜I Dá»ŠCH Bá»Š CHáº¶N HOÃ€N TOÃ€N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N - KHÃ”NG CÃ“ á»¨NG Cá»¬ VIÃŠN]", True, False)

        # 3. Kiá»ƒm tra lÃ½ do káº¿t thÃºc cá»§a á»©ng cá»­ viÃªn Ä‘áº§u tiÃªn (náº¿u cÃ³)
        first_candidate = response.candidates[0]
        if first_candidate.finish_reason == 'SAFETY':
            blocked_categories = [
                rating.category.name for rating in first_candidate.safety_ratings
                if rating.blocked
            ]
            return (f"[Ná»˜I Dá»ŠCH Bá»Š CHáº¶N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N - OUTPUT: {', '.join(blocked_categories)}]", True, False)

        # Náº¿u khÃ´ng bá»‹ cháº·n, tráº£ vá» vÄƒn báº£n dá»‹ch
        translated_text = response.text
        is_bad = is_bad_translation(translated_text)
        return (translated_text, False, is_bad)

    except Exception as e:
        # Báº¯t cÃ¡c lá»—i khÃ¡c (vÃ­ dá»¥: lá»—i máº¡ng, lá»—i API)
        return (f"[Lá»–I API KHI Dá»ŠCH CHUNK: {e}]", False, True)

def get_progress(progress_file_path):
    """Äá»c tiáº¿n Ä‘á»™ dá»‹ch tá»« file (sá»‘ chunk Ä‘Ã£ hoÃ n thÃ nh)."""
    if os.path.exists(progress_file_path):
        try:
            with open(progress_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # LÆ°u sá»‘ chunk Ä‘Ã£ hoÃ n thÃ nh
                return data.get('completed_chunks', 0)
        except json.JSONDecodeError:
            print(f"Cáº£nh bÃ¡o: File tiáº¿n Ä‘á»™ '{progress_file_path}' bá»‹ há»ng hoáº·c khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng JSON. Báº¯t Ä‘áº§u tá»« Ä‘áº§u.")
            return 0
    return 0

def save_progress(progress_file_path, completed_chunks):
    """LÆ°u tiáº¿n Ä‘á»™ dá»‹ch (sá»‘ chunk Ä‘Ã£ hoÃ n thÃ nh) vÃ o file."""
    try:
        with open(progress_file_path, 'w', encoding='utf-8') as f:
            json.dump({
                'completed_chunks': completed_chunks
            }, f)
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi lÆ°u file tiáº¿n Ä‘á»™: {e}")

def process_chunk(api_key, model_name, system_instruction, chunk_data, log_callback=None):
    """
    Xá»­ lÃ½ dá»‹ch má»™t chunk vá»›i retry logic.
    chunk_data: tuple (chunk_index, chunk_lines, chunk_start_line_index)
    Tráº£ vá»: (chunk_index, translated_text, lines_count)
    """
    chunk_index, chunk_lines, chunk_start_line_index = chunk_data
    
    # Kiá»ƒm tra flag dá»«ng trÆ°á»›c khi báº¯t Ä‘áº§u
    if is_translation_stopped():
        return (chunk_index, f"[CHUNK {chunk_index} Bá»Š Dá»ªNG Bá»I NGÆ¯á»œI DÃ™NG]", len(chunk_lines))
    
    # Cáº¥u hÃ¬nh API cho thread hiá»‡n táº¡i
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(
        model_name=model_name,
        system_instruction=system_instruction,
    )
    
    # Thá»­ láº¡i vá»›i lá»—i báº£o máº­t
    safety_retries = 0
    is_safety_blocked = False  # Khá»Ÿi táº¡o biáº¿n
    while safety_retries < MAX_RETRIES_ON_SAFETY_BLOCK:
        # Kiá»ƒm tra flag dá»«ng trong quÃ¡ trÃ¬nh retry
        if is_translation_stopped():
            return (chunk_index, f"[CHUNK {chunk_index} Bá»Š Dá»ªNG Bá»I NGÆ¯á»œI DÃ™NG]", len(chunk_lines))
            
        # Thá»­ láº¡i vá»›i báº£n dá»‹ch xáº¥u  
        bad_translation_retries = 0
        while bad_translation_retries < MAX_RETRIES_ON_BAD_TRANSLATION:
            # Kiá»ƒm tra flag dá»«ng trong quÃ¡ trÃ¬nh retry
            if is_translation_stopped():
                return (chunk_index, f"[CHUNK {chunk_index} Bá»Š Dá»ªNG Bá»I NGÆ¯á»œI DÃ™NG]", len(chunk_lines))
                
            try:
                translated_text, is_safety_blocked, is_bad = translate_chunk(model, chunk_lines)
                
                if is_safety_blocked:
                    break # ThoÃ¡t khá»i vÃ²ng láº·p bad translation, sáº½ retry safety
                    
                if not is_bad:
                    return (chunk_index, translated_text, len(chunk_lines)) # ThÃ nh cÃ´ng
                    
                # Báº£n dá»‹ch xáº¥u, thá»­ láº¡i
                bad_translation_retries += 1
                if bad_translation_retries < MAX_RETRIES_ON_BAD_TRANSLATION:
                    time.sleep(RETRY_DELAY_SECONDS)
                else:
                    # Háº¿t láº§n thá»­ bad translation, dÃ¹ng báº£n dá»‹ch cuá»‘i
                    return (chunk_index, translated_text + " [KHÃ”NG Cáº¢I THIá»†N ÄÆ¯á»¢C]", len(chunk_lines))
                    
            except Exception as e:
                return (chunk_index, f"[Lá»–I Xá»¬ LÃ CHUNK {chunk_index}: {e}]", len(chunk_lines))
        
        # Náº¿u bá»‹ cháº·n safety, thá»­ láº¡i
        if is_safety_blocked:
            safety_retries += 1
            if safety_retries < MAX_RETRIES_ON_SAFETY_BLOCK:
                time.sleep(RETRY_DELAY_SECONDS)
            else:
                # Háº¿t láº§n thá»­ safety, tráº£ vá» thÃ´ng bÃ¡o lá»—i
                return (chunk_index, translated_text, len(chunk_lines))
    
    # Fallback (khÃ´ng nÃªn Ä‘áº¿n Ä‘Ã¢y)
    return (chunk_index, f"[KHÃ”NG THá»‚ Dá»ŠCH CHUNK {chunk_index}]", len(chunk_lines))

def generate_output_filename(input_filepath):
    """
    Tá»± Ä‘á»™ng táº¡o tÃªn file output tá»« input file.
    VÃ­ dá»¥: "test.txt" -> "test_TranslateAI.txt"
    """
    # TÃ¡ch tÃªn file vÃ  pháº§n má»Ÿ rá»™ng
    file_dir = os.path.dirname(input_filepath)
    file_name = os.path.basename(input_filepath)
    name_without_ext, ext = os.path.splitext(file_name)
    
    # Táº¡o tÃªn file má»›i
    new_name = f"{name_without_ext}_TranslateAI{ext}"
    
    # Káº¿t há»£p vá»›i thÆ° má»¥c (náº¿u cÃ³)
    if file_dir:
        return os.path.join(file_dir, new_name)
    else:
        return new_name

def translate_file_optimized(input_file, output_file=None, api_key=None, model_name="gemini-2.0-flash", system_instruction=None, num_workers=None, chunk_size_lines=None):
    """
    PhiÃªn báº£n dá»‹ch file vá»›i multi-threading chunks.
    """
    # Clear stop flag khi báº¯t Ä‘áº§u dá»‹ch má»›i
    clear_stop_translation()
    
    # Validate vÃ  thiáº¿t láº­p parameters
    if num_workers is None:
        num_workers = NUM_WORKERS
    else:
        num_workers = validate_threads(num_workers)
        
    if chunk_size_lines is None:
        chunk_size_lines = CHUNK_SIZE_LINES
    else:
        chunk_size_lines = validate_chunk_size(chunk_size_lines)
    
    # Tá»± Ä‘á»™ng táº¡o tÃªn file output náº¿u khÃ´ng Ä‘Æ°á»£c cung cáº¥p
    if output_file is None:
        output_file = generate_output_filename(input_file)
        print(f"ğŸ“ Tá»± Ä‘á»™ng táº¡o tÃªn file output: {output_file}")
    
    print(f"Báº¯t Ä‘áº§u dá»‹ch file: {input_file}")
    print(f"File output: {output_file}")
    print(f"Sá»‘ worker threads: {num_workers}")
    print(f"KÃ­ch thÆ°á»›c chunk: {chunk_size_lines} dÃ²ng")

    progress_file_path = f"{input_file}{PROGRESS_FILE_SUFFIX}"

    # Láº¥y tiáº¿n Ä‘á»™ tá»« file - sá»‘ chunk Ä‘Ã£ hoÃ n thÃ nh
    completed_chunks = get_progress(progress_file_path)
    print(f"ÄÃ£ hoÃ n thÃ nh {completed_chunks} chunk trÆ°á»›c Ä‘Ã³.")

    # Thá»i gian báº¯t Ä‘áº§u Ä‘á»ƒ tÃ­nh hiá»‡u suáº¥t
    start_time = time.time()
    
    # System instruction cho AI - sá»­ dá»¥ng custom hoáº·c default
    if system_instruction is None:
        system_instruction = "Dá»‹ch vÄƒn báº£n sau sang tiáº¿ng Viá»‡t. Bá»‘i cáº£nh hiá»‡n Ä‘áº¡i. Äáº£m báº£o cÃ¡c cÃ¢u thoáº¡i nhÃ¢n váº­t Ä‘Æ°á»£c dá»‹ch chÃ­nh xÃ¡c vÃ  Ä‘áº·c trong dáº¥u "". Äáº£m báº£o giá»¯ nguyÃªn chi tiáº¿t ná»™i dung. Giá»¯ nguyÃªn cÃ¡c tá»« ngá»¯ thÃ´ tá»¥c, tÃ¬nh dá»¥c."
    
    print(f"ğŸ¯ System instruction: {system_instruction[:100]}...")  # Log first 100 chars

    try:
        # Äá»c toÃ n bá»™ file vÃ  chia thÃ nh chunks
        with open(input_file, 'r', encoding='utf-8', errors='replace') as infile:
            all_lines = infile.readlines()
        
        total_lines = len(all_lines)
        print(f"Tá»•ng sá»‘ dÃ²ng trong file: {total_lines}")
        
        # Chia thÃ nh chunks
        chunks = []
        for i in range(0, total_lines, chunk_size_lines):
            chunk_lines = all_lines[i:i + chunk_size_lines]
            chunks.append((len(chunks), chunk_lines, i))  # (chunk_index, chunk_lines, start_line_index)
        
        total_chunks = len(chunks)
        print(f"Tá»•ng sá»‘ chunks: {total_chunks}")
        
        # Kiá»ƒm tra náº¿u Ä‘Ã£ dá»‹ch háº¿t file rá»“i
        if completed_chunks >= total_chunks:
            print(f"âœ… File Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch hoÃ n toÃ n ({completed_chunks}/{total_chunks} chunks).")
            if os.path.exists(progress_file_path):
                os.remove(progress_file_path)
                print(f"ÄÃ£ xÃ³a file tiáº¿n Ä‘á»™: {os.path.basename(progress_file_path)}")
            return True

        # Má»Ÿ file output Ä‘á»ƒ ghi káº¿t quáº£
        mode = 'a' if completed_chunks > 0 else 'w'  # Append náº¿u cÃ³ tiáº¿n Ä‘á»™ cÅ©, write náº¿u báº¯t Ä‘áº§u má»›i
        with open(output_file, mode, encoding='utf-8') as outfile:
            
            # Dictionary Ä‘á»ƒ lÆ°u trá»¯ káº¿t quáº£ dá»‹ch theo thá»© tá»± chunk index
            translated_chunks_results = {}
            next_expected_chunk_to_write = completed_chunks
            total_lines_processed = completed_chunks * chunk_size_lines

            with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
                
                futures = {} # LÆ°u trá»¯ cÃ¡c future: {future_object: chunk_index}
                
                # Gá»­i cÃ¡c chunks cáº§n dá»‹ch Ä‘áº¿n thread pool
                chunks_to_process = chunks[completed_chunks:]  # Chá»‰ xá»­ lÃ½ chunks chÆ°a hoÃ n thÃ nh
                
                print(f"Gá»­i {len(chunks_to_process)} chunks Ä‘áº¿n thread pool...")
                
                for chunk_data in chunks_to_process:
                    # Kiá»ƒm tra flag dá»«ng trÆ°á»›c khi submit
                    if is_translation_stopped():
                        print("ğŸ›‘ Dá»«ng gá»­i chunks má»›i do ngÆ°á»i dÃ¹ng yÃªu cáº§u")
                        break
                        
                    future = executor.submit(process_chunk, api_key, model_name, system_instruction, chunk_data)
                    futures[future] = chunk_data[0]  # chunk_index
                
                # Thu tháº­p káº¿t quáº£ khi cÃ¡c threads hoÃ n thÃ nh
                for future in concurrent.futures.as_completed(futures):
                    # Kiá»ƒm tra flag dá»«ng
                    if is_translation_stopped():
                        print("ğŸ›‘ Dá»«ng xá»­ lÃ½ káº¿t quáº£ do ngÆ°á»i dÃ¹ng yÃªu cáº§u")
                        # Há»§y cÃ¡c future chÆ°a hoÃ n thÃ nh
                        for f in futures:
                            if not f.done():
                                f.cancel()
                        break
                        
                    chunk_index = futures[future]
                    try:
                        result = future.result()  # (chunk_index, translated_text, lines_count)
                        processed_chunk_index, translated_text, lines_count = result
                        
                        # LÆ°u káº¿t quáº£ vÃ o buffer táº¡m chá» ghi theo thá»© tá»±
                        translated_chunks_results[processed_chunk_index] = (translated_text, lines_count)
                        
                        print(f"âœ… HoÃ n thÃ nh chunk {processed_chunk_index + 1}/{total_chunks}")
                        
                        # Ghi cÃ¡c chunks Ä‘Ã£ hoÃ n thÃ nh vÃ o file output theo Ä‘Ãºng thá»© tá»±
                        while next_expected_chunk_to_write in translated_chunks_results:
                            chunk_text, chunk_lines_count = translated_chunks_results.pop(next_expected_chunk_to_write)
                            outfile.write(chunk_text)
                            if not chunk_text.endswith('\n'):
                                outfile.write('\n')
                            outfile.flush()
                            
                            # Cáº­p nháº­t tiáº¿n Ä‘á»™
                            next_expected_chunk_to_write += 1
                            total_lines_processed += chunk_lines_count
                            
                            # LÆ°u tiáº¿n Ä‘á»™ sau má»—i chunk hoÃ n thÃ nh
                            save_progress(progress_file_path, next_expected_chunk_to_write)
                            
                            # Hiá»ƒn thá»‹ thÃ´ng tin tiáº¿n Ä‘á»™
                            current_time = time.time()
                            elapsed_time = current_time - start_time
                            progress_percent = (next_expected_chunk_to_write / total_chunks) * 100
                            avg_speed = total_lines_processed / elapsed_time if elapsed_time > 0 else 0
                            
                            print(f"Tiáº¿n Ä‘á»™: {next_expected_chunk_to_write}/{total_chunks} chunks ({progress_percent:.1f}%) - {avg_speed:.1f} dÃ²ng/giÃ¢y")
                            
                    except Exception as e:
                        print(f"âŒ Lá»—i khi xá»­ lÃ½ chunk {chunk_index}: {e}")
                
                # Ghi ná»‘t cÃ¡c chunks cÃ²n sÃ³t láº¡i trong buffer (náº¿u cÃ³)
                if translated_chunks_results:
                    print("âš ï¸ Ghi cÃ¡c chunks cÃ²n sÃ³t láº¡i...")
                    sorted_remaining_chunks = sorted(translated_chunks_results.items())
                    for chunk_idx, (chunk_text, chunk_lines_count) in sorted_remaining_chunks:
                        try:
                            outfile.write(chunk_text)
                            if not chunk_text.endswith('\n'):
                                outfile.write('\n')
                            outfile.flush()
                            next_expected_chunk_to_write += 1
                            save_progress(progress_file_path, next_expected_chunk_to_write)
                            print(f"âœ… Ghi chunk bá»‹ sÃ³t: {chunk_idx + 1}")
                        except Exception as e:
                            print(f"âŒ Lá»—i khi ghi chunk {chunk_idx}: {e}")

        # Kiá»ƒm tra xem cÃ³ bá»‹ dá»«ng giá»¯a chá»«ng khÃ´ng
        if is_translation_stopped():
            print(f"ğŸ›‘ Tiáº¿n trÃ¬nh dá»‹ch Ä‘Ã£ bá»‹ dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng.")
            print(f"ÄÃ£ xá»­ lÃ½ {next_expected_chunk_to_write}/{total_chunks} chunks.")
            print(f"ğŸ’¾ Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c dá»‹ch sau.")
            return False

        # HoÃ n thÃ nh
        total_time = time.time() - start_time
        if next_expected_chunk_to_write >= total_chunks:
            print(f"âœ… Dá»‹ch hoÃ n thÃ nh file: {os.path.basename(input_file)}")
            print(f"ÄÃ£ dá»‹ch {total_chunks} chunks ({total_lines} dÃ²ng) trong {total_time:.2f}s")
            print(f"Tá»‘c Ä‘á»™ trung bÃ¬nh: {total_lines / total_time:.2f} dÃ²ng/giÃ¢y")
            print(f"File dá»‹ch Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_file}")

            # XÃ³a file tiáº¿n Ä‘á»™ khi hoÃ n thÃ nh
            if os.path.exists(progress_file_path):
                os.remove(progress_file_path)
                print(f"ÄÃ£ xÃ³a file tiáº¿n Ä‘á»™: {os.path.basename(progress_file_path)}")
            
            # Tá»± Ä‘á»™ng reformat file sau khi dá»‹ch xong
            if CAN_REFORMAT:
                print("\nğŸ”§ Báº¯t Ä‘áº§u reformat file Ä‘Ã£ dá»‹ch...")
                try:
                    fix_text_format(output_file)
                    print("âœ… Reformat hoÃ n thÃ nh!")
                except Exception as e:
                    print(f"âš ï¸ Lá»—i khi reformat: {e}")
            else:
                print("âš ï¸ Chá»©c nÄƒng reformat khÃ´ng kháº£ dá»¥ng")
            
            return True
        else:
            print(f"âš ï¸ QuÃ¡ trÃ¬nh dá»‹ch bá»‹ giÃ¡n Ä‘oáº¡n.")
            print(f"ÄÃ£ xá»­ lÃ½ {next_expected_chunk_to_write}/{total_chunks} chunks.")
            print(f"Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. Báº¡n cÃ³ thá»ƒ cháº¡y láº¡i chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ tiáº¿p tá»¥c.")
            return False

    except FileNotFoundError:
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file Ä‘áº§u vÃ o '{input_file}'.")
        return False
    except Exception as e:
        print(f"âŒ ÄÃ£ xáº£y ra lá»—i khÃ´ng mong muá»‘n: {e}")
        print("Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. Báº¡n cÃ³ thá»ƒ cháº¡y láº¡i chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ tiáº¿p tá»¥c.")
        return False


def load_api_key():
    """Tá»± Ä‘á»™ng load API key tá»« environment variable hoáº·c file config"""
    # Thá»­ load tá»« environment variable
    import os
    api_key = os.getenv('GOOGLE_AI_API_KEY')
    if api_key:
        print(f"âœ… ÄÃ£ load API key tá»« environment variable")
        return api_key
    
    # Thá»­ load tá»« file config.json
    try:
        if os.path.exists('config.json'):
            with open('config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                api_key = config.get('api_key')
                if api_key:
                    print(f"âœ… ÄÃ£ load API key tá»« config.json")
                    return api_key
    except:
        pass
    
    return None

def main():
    """Interactive main function for command line usage"""
    print("=== TranslateNovelAI - Command Line Version ===\n")
    
    # Thá»­ tá»± Ä‘á»™ng load API Key
    api_key = load_api_key()
    
    if not api_key:
        # Nháº­p API Key manually
        api_key = input("Nháº­p Google AI API Key: ").strip()
        if not api_key:
            print("âŒ API Key khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")
            return
        
        # Há»i cÃ³ muá»‘n lÆ°u vÃ o config.json khÃ´ng
        save_key = input("ğŸ’¾ LÆ°u API key vÃ o config.json? (y/N): ").lower().strip()
        if save_key == 'y':
            try:
                config = {'api_key': api_key}
                with open('config.json', 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2)
                print("âœ… ÄÃ£ lÆ°u API key vÃ o config.json")
            except Exception as e:
                print(f"âš ï¸ Lá»—i lÆ°u config: {e}")
    else:
        print(f"ğŸ”‘ API Key: {api_key[:10]}***{api_key[-10:]}")
    
    # Nháº­p Ä‘Æ°á»ng dáº«n file input
    input_file = input("Nháº­p Ä‘Æ°á»ng dáº«n file truyá»‡n cáº§n dá»‹ch: ").strip()
    if not input_file:
        print("âŒ ÄÆ°á»ng dáº«n file khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")
        return
    
    # Kiá»ƒm tra file tá»“n táº¡i
    if not os.path.exists(input_file):
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {input_file}")
        return
    
    # TÃ¹y chá»n file output (cÃ³ thá»ƒ Ä‘á»ƒ trá»‘ng)
    output_file = input("Nháº­p Ä‘Æ°á»ng dáº«n file output (Ä‘á»ƒ trá»‘ng Ä‘á»ƒ tá»± Ä‘á»™ng táº¡o): ").strip()
    if not output_file:
        output_file = None
        print("ğŸ“ Sáº½ tá»± Ä‘á»™ng táº¡o tÃªn file output")
    
    # TÃ¹y chá»n model
    print("\nChá»n model:")
    print("1. gemini-2.0-flash (khuyáº¿n nghá»‹)")
    print("2. gemini-1.5-flash")
    print("3. gemini-1.5-pro")
    
    model_choice = input("Nháº­p lá»±a chá»n (1-3, máº·c Ä‘á»‹nh 1): ").strip()
    model_map = {
        "1": "gemini-2.0-flash",
        "2": "gemini-1.5-flash", 
        "3": "gemini-1.5-pro",
        "": "gemini-2.0-flash"  # Default
    }
    
    model_name = model_map.get(model_choice, "gemini-2.0-flash")
    print(f"ğŸ“± Sá»­ dá»¥ng model: {model_name}")
    
    # XÃ¡c nháº­n trÆ°á»›c khi báº¯t Ä‘áº§u
    print(f"\nğŸ“‹ ThÃ´ng tin dá»‹ch:")
    print(f"  Input: {input_file}")
    print(f"  Output: {output_file or 'Tá»± Ä‘á»™ng táº¡o'}")
    print(f"  Model: {model_name}")
    print(f"  Threads: {get_optimal_threads()}")
    print(f"  Chunk size: {CHUNK_SIZE_LINES} dÃ²ng")
    
    confirm = input("\nğŸš€ Báº¯t Ä‘áº§u dá»‹ch? (y/N): ").lower().strip()
    if confirm != 'y':
        print("âŒ Há»§y bá».")
        return
    
    # Báº¯t Ä‘áº§u dá»‹ch
    print("\n" + "="*50)
    try:
        success = translate_file_optimized(
            input_file=input_file,
            output_file=output_file,
            api_key=api_key,
            model_name=model_name
        )
        
        if success:
            print("\nğŸ‰ Dá»‹ch hoÃ n thÃ nh thÃ nh cÃ´ng!")
        else:
            print("\nâš ï¸ Dá»‹ch chÆ°a hoÃ n thÃ nh.")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ NgÆ°á»i dÃ¹ng dá»«ng chÆ°Æ¡ng trÃ¬nh.")
        print("ğŸ’¾ Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u, cÃ³ thá»ƒ tiáº¿p tá»¥c sau.")
    except Exception as e:
        print(f"\nâŒ Lá»—i khÃ´ng mong muá»‘n: {e}")


if __name__ == "__main__":
    main()